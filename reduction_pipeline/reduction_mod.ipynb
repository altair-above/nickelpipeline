{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this notebook to reduce data from the Nickel Telescope. Be sure to read the notes in between the cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from astropy.io import fits\n",
    "from pathlib import Path\n",
    "\n",
    "from overscan_subtraction import overscan_subtraction\n",
    "from bias_subtraction import bias_subtraction\n",
    "from dark_subtraction import dark_subtraction\n",
    "from flat_division import flat_division\n",
    "from correct_object_name import correct_object_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reduction requires the OBJECT names in the raw FITS files (which are set at the time of the observation) to be one of the following:\n",
    "- \"bias\"\n",
    "- \"dark\"\n",
    "- \"dome flat\"\n",
    "- \"sky flat\" (i.e., flats taken of the sky at sunset)\n",
    "- \"focus\"\n",
    "- your target names (can be anything)\n",
    "\n",
    "If you need to correct OBJECT an in FITS headers of any files, do that below. If everything is correct, ignore the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct_object(myfiles, \"dark\")\n",
    "\n",
    "# # Set object type names\n",
    "bias_object = 'Bias'\n",
    "dome_flat_object = 'Dome flat'\n",
    "sky_flat_object = 'Flat'\n",
    "dark_object = 'dark'\n",
    "focus_object = 'focus'\n",
    "\n",
    "# bias_object = 'bias'\n",
    "# dome_flat_object = 'flat'\n",
    "# sky_flat_object = 'sky flat'\n",
    "# dark_object = 'dark'\n",
    "# focus_object = 'focus'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you're ready to reduce your data. First, get a list of all the raw data files. The name of the directory with the raw data should have format 'YYYY-MM-DD-nickel-raw'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rawdir = Path(\"C:/Users/allis/Documents/2024-2025_Local/Akamai Internship/pipeline-testing/2024-05-12/raw\")  # path to directory with raw data\n",
    "# rawdir = Path(\"C:/Users/allis/Documents/2024-2025_Local/Akamai Internship/pipeline-testing/test-data-05-12/raw\")  # path to directory with raw data\n",
    "# rawdir = Path(\"C:/Users/allis/Documents/2024-2025_Local/Akamai Internship/pipeline-testing/test-data-06-24/raw\")  # path to directory with raw data\n",
    "rawdir = Path(\"C:/Users/allis/Documents/2024-2025_Local/Akamai Internship/pipeline-testing/test-data-06-26/raw\")\n",
    "rawfiles = [file for file in rawdir.iterdir() if file.is_file()]\n",
    "\n",
    "# # Deletes bad flats from the 05-12-24 data run\n",
    "# rawfiles = rawfiles[:36] + rawfiles[41:]\n",
    "\n",
    "# Deletes bad files from the 06-26-24 data run\n",
    "del rawfiles[115]\n",
    "del rawfiles[112:114]\n",
    "del rawfiles[108:110]\n",
    "del rawfiles[74:78]\n",
    "del rawfiles[34]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create processing and reduced directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir = rawdir.parent\n",
    "procdir = rawdir.parent / (rawdir.name + \"-proc\")\n",
    "reddir = rawdir.parent / (rawdir.name + \"-reduced\")\n",
    "\n",
    "Path.mkdir(procdir, exist_ok=True)\n",
    "Path.mkdir(reddir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do overscan subtraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\allis\\Documents\\2024-2025_Local\\Akamai Internship\\pipeline-testing\\test-data-06-26\\raw-proc\\overscan\n"
     ]
    }
   ],
   "source": [
    "overscan_dir = procdir / 'overscan'\n",
    "print(overscan_dir)\n",
    "Path.mkdir(overscan_dir, exist_ok=True)\n",
    "overscan_files = [overscan_dir / (file.stem + file.suffix) for file in rawfiles]\n",
    "\n",
    "overscan_subtraction(rawfiles, overscan_files, 'yes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a dataframe of all the files we want to continue reducing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>object</th>\n",
       "      <th>exptime</th>\n",
       "      <th>filt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6563/100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...</td>\n",
       "      <td>Bias</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6563/100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...</td>\n",
       "      <td>Bias</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6563/100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...</td>\n",
       "      <td>Bias</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6563/100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...</td>\n",
       "      <td>Bias</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6563/100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...</td>\n",
       "      <td>Flat</td>\n",
       "      <td>10.0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...</td>\n",
       "      <td>Flat</td>\n",
       "      <td>10.0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...</td>\n",
       "      <td>Flat</td>\n",
       "      <td>10.0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...</td>\n",
       "      <td>Flat</td>\n",
       "      <td>10.0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...</td>\n",
       "      <td>Flat</td>\n",
       "      <td>10.0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  file object  exptime  \\\n",
       "0    C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...   test      0.0   \n",
       "1    C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...   Bias      0.0   \n",
       "2    C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...   Bias      0.0   \n",
       "3    C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...   Bias      0.0   \n",
       "4    C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...   Bias      0.0   \n",
       "..                                                 ...    ...      ...   \n",
       "107  C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...   Flat     10.0   \n",
       "108  C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...   Flat     10.0   \n",
       "109  C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...   Flat     10.0   \n",
       "110  C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...   Flat     10.0   \n",
       "111  C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...   Flat     10.0   \n",
       "\n",
       "         filt  \n",
       "0    6563/100  \n",
       "1    6563/100  \n",
       "2    6563/100  \n",
       "3    6563/100  \n",
       "4    6563/100  \n",
       "..        ...  \n",
       "107         B  \n",
       "108         B  \n",
       "109         B  \n",
       "110         B  \n",
       "111         B  \n",
       "\n",
       "[112 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_list = []\n",
    "exptime_list = []\n",
    "filt_list = []\n",
    "\n",
    "for overscan_file in overscan_files:\n",
    "    hdul = fits.open(str(overscan_file))\n",
    "    obj_list.append(hdul[0].header[\"OBJECT\"])\n",
    "    exptime_list.append(hdul[0].header[\"EXPTIME\"])\n",
    "    filt_list.append(hdul[0].header[\"FILTNAM\"])\n",
    "    hdul.close()\n",
    "\n",
    "df_log = pd.DataFrame({\n",
    "    \"file\": overscan_files,\n",
    "    \"object\": obj_list,\n",
    "    \"exptime\": exptime_list,\n",
    "    \"filt\": filt_list\n",
    "    })\n",
    "df_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do bias subtraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\allis\\Documents\\2024-2025_Local\\Akamai Internship\\pipeline-testing\\test-data-06-26\\raw-proc\\unbias\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>object</th>\n",
       "      <th>exptime</th>\n",
       "      <th>filt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6563/100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...</td>\n",
       "      <td>Bias</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6563/100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...</td>\n",
       "      <td>Bias</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6563/100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...</td>\n",
       "      <td>Bias</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6563/100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...</td>\n",
       "      <td>Bias</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6563/100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...</td>\n",
       "      <td>Flat</td>\n",
       "      <td>10.0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...</td>\n",
       "      <td>Flat</td>\n",
       "      <td>10.0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...</td>\n",
       "      <td>Flat</td>\n",
       "      <td>10.0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...</td>\n",
       "      <td>Flat</td>\n",
       "      <td>10.0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...</td>\n",
       "      <td>Flat</td>\n",
       "      <td>10.0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  file object  exptime  \\\n",
       "0    C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...   test      0.0   \n",
       "1    C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...   Bias      0.0   \n",
       "2    C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...   Bias      0.0   \n",
       "3    C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...   Bias      0.0   \n",
       "4    C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...   Bias      0.0   \n",
       "..                                                 ...    ...      ...   \n",
       "107  C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...   Flat     10.0   \n",
       "108  C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...   Flat     10.0   \n",
       "109  C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...   Flat     10.0   \n",
       "110  C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...   Flat     10.0   \n",
       "111  C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...   Flat     10.0   \n",
       "\n",
       "         filt  \n",
       "0    6563/100  \n",
       "1    6563/100  \n",
       "2    6563/100  \n",
       "3    6563/100  \n",
       "4    6563/100  \n",
       "..        ...  \n",
       "107         B  \n",
       "108         B  \n",
       "109         B  \n",
       "110         B  \n",
       "111         B  \n",
       "\n",
       "[112 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gather all the bias frames\n",
    "biasfiles = list(df_log.file[df_log.object == bias_object])\n",
    "\n",
    "# average all of them into one\n",
    "biasdata = []\n",
    "for biasfile in biasfiles:\n",
    "    hdul = fits.open(str(biasfile))\n",
    "    biasdata.append(hdul[0].data)\n",
    "    hdul.close()\n",
    "bias = np.stack(biasdata).mean(axis=0)\n",
    "\n",
    "# omit hot column so that it is properly flat-fielded out\n",
    "# Allison Note: column is saturated to around 65,000 cts in all images; unusable (???)\n",
    "bias[:,256] = 0\n",
    "\n",
    "# gather all non-bias files in a subdirectory of -proc\n",
    "nonbias_dir = procdir / 'unbias'\n",
    "print(nonbias_dir)\n",
    "Path.mkdir(nonbias_dir, exist_ok=True)\n",
    "\n",
    "nonbias_files_input = list(df_log.file[df_log.object != bias_object])\n",
    "nonbias_files_output = [nonbias_dir / (file.stem.split('_')[0] + file.suffix) for file in nonbias_files_input]\n",
    "\n",
    "bias_subtraction(nonbias_files_input, nonbias_files_output, bias)\n",
    "\n",
    "df_log[\"file\"] = [nonbias_dir / (file.stem.split('_')[0] + file.suffix) for file in df_log[\"file\"]]\n",
    "df_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do dark subtraction.\n",
    "\n",
    "This can usually be skipped, since the Nickel CCD has a very low dark current, but it is included here for the sake of completeness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code deleted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do flat division.\n",
    "\n",
    "Divide each pixel and then multiply all pixels by the average of the flat frame.\n",
    "\n",
    "If sky (sunset) flats are available, those are used. If they are not available, dome flats are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use sky flats if available, use dome flats if not\n",
    "if sky_flat_object in list(set(obj_list)):\n",
    "    flattype = sky_flat_object\n",
    "else:\n",
    "    flattype = dome_flat_object\n",
    "    \n",
    "flatfilts = list(set(df_log.filt[df_log.object == flattype]))\n",
    "\n",
    "for flatfilt in flatfilts:\n",
    "    # find all the files with this filter\n",
    "    flatfiles = list(df_log.file[(df_log.object == flattype) & (df_log.filt == flatfilt)])\n",
    "    scienceobjects = list(set(df_log.object[(df_log.object != bias_object) &\n",
    "                                            (df_log.object != dark_object) &\n",
    "                                            (df_log.object != dome_flat_object) &    # modified from 'dome flat' to 'flat' for 05-12-24 data\n",
    "                                            (df_log.object != sky_flat_object) &\n",
    "                                            (df_log.object != focus_object) &\n",
    "                                            (df_log.filt == flatfilt)]))\n",
    "    \n",
    "    # calculate the average flat frame\n",
    "    if len(flatfiles) > 1:\n",
    "        flatdata = []\n",
    "        for flatfile in flatfiles:\n",
    "            hdul = fits.open(str(flatfile))\n",
    "            flatdata.append(hdul[0].data)\n",
    "            hdul.close()\n",
    "        flat = np.stack(flatdata).mean(axis=0)\n",
    "    else:\n",
    "        hdul = fits.open(str(flatfiles[0]))\n",
    "        flat = hdul[0].data\n",
    "        hdul.close()\n",
    "        \n",
    "    if len(scienceobjects) > 0:\n",
    "        for scienceobject in scienceobjects:\n",
    "            sciencefiles = list(df_log.file[(df_log.object == scienceobject) &\n",
    "                                            (df_log.filt == flatfilt)])\n",
    "            \n",
    "            # make a new directory for each science target / filter combination\n",
    "            sci_dir = reddir / (scienceobject + '_' + flatfilt)\n",
    "            Path.mkdir(sci_dir, exist_ok=True)\n",
    "\n",
    "            # define reduced file names\n",
    "            redfiles = [sci_dir / (file.stem.split('_')[0] + '_red' + file.suffix) for file in sciencefiles]\n",
    "\n",
    "            # do flat division\n",
    "            if len(sciencefiles) > 0:\n",
    "                flat_division(sciencefiles, redfiles, flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You're done! Your reduced images are now ready for your viewing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete all overscan subtracted files to save memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for file in overscan_files:\n",
    "#     file.unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the code below to go back through and check values in the FITS files (- Allison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Examining average column value of hot column 257 -- data unusable in this column; saturated pixels\n",
    "# for image in rawfiles:\n",
    "#     with fits.open(image, mode='update') as hdu:\n",
    "#         data = hdu[0].data\n",
    "#         header = hdu[0].header\n",
    "#         impath = header[\"FITSFILE\"]\n",
    "#         objtype = header[\"OBJECT\"]\n",
    "#         print(f\"Image {impath} (type {objtype}) has avg value in hot column 257 = {np.mean(data[:,256]):.1f}\")\n",
    "\n",
    "# # Examining hot column 1003 vs regular column 1000\n",
    "# # Inconsistent ratio and difference (uncorrelated w/ exposure time?)\n",
    "# for image in rawfiles:\n",
    "#     with fits.open(image, mode='update') as hdu:\n",
    "#         data = hdu[0].data\n",
    "#         header = hdu[0].header\n",
    "#         # impath = header[\"FITSFILE\"]\n",
    "#         objtype = header[\"OBJECT\"]\n",
    "#         exptime = header[\"EXPTIME\"]\n",
    "#         print(f\"Image {image.name} ({objtype}, {exptime}): col 1003 avg = {np.mean(data[:,1002]):.1f}, col 1000 avg = {np.mean(data[:,999]):.1f}. diff = {np.mean(data[:,784])-np.mean(data[:,783]):.3f}, ratio = {np.mean(data[:,1002])/np.mean(data[:,999]):.2f}\")\n",
    "\n",
    "# # Examining difference between dull column 784 and bright column 785\n",
    "# for image in rawfiles:\n",
    "#     with fits.open(image, mode='update') as hdu:\n",
    "#         data = hdu[0].data\n",
    "#         header = hdu[0].header\n",
    "#         # impath = header[\"FITSFILE\"]\n",
    "#         objtype = header[\"OBJECT\"]\n",
    "#         exptime = header[\"EXPTIME\"]\n",
    "#         print(f\"Image {image.name} ({objtype}, {exptime}): col 784 avg = {np.mean(data[:,783]):.1f}, col 785 avg = {np.mean(data[:,784]):.1f}. diff = {np.mean(data[:,784])-np.mean(data[:,783]):.3f}, ratio = {np.mean(data[:,784])/np.mean(data[:,783]):.2f}\")\n",
    "\n",
    "# Make sure that all filter names are correct\n",
    "# for sci_image in rawfiles[44:]:\n",
    "#     with fits.open(sci_image, mode='update') as hdu:\n",
    "#         header = hdu[0].header\n",
    "#         header[\"FILTNAM\"] = \"V\"\n",
    "#         hdu.flush()\n",
    "\n",
    "# with fits.open(\"C:/Users/allis/Documents/2024-2025_Local/Akamai Internship/pipeline-testing/test-data-05-12/raw/d1076.fits\", mode='update') as hdu:\n",
    "#     header = hdu[0].header\n",
    "#     header[\"FILTNAM\"] = \"I\"\n",
    "#     hdu.flush()\n",
    "\n",
    "# # Display many files in a row\n",
    "# import matplotlib.pyplot as plt\n",
    "# display_dir = Path(\"C:/Users/allis/Documents/2024-2025_Local/Akamai Internship/pipeline-testing/test-data-05-12/raw-reduced/sky flat_V\")\n",
    "# for image in display_dir.iterdir():\n",
    "#     with fits.open(image) as hdul:\n",
    "#         # print(\"HDU List Info:\")\n",
    "#         # print(hdul.info())\n",
    "#         # print(\"\\nHDU Header\")\n",
    "#         # print(repr(hdul[0].header))\n",
    "        \n",
    "#         # print(hdul[0].data)\n",
    "        \n",
    "#         plt.figure(figsize=(4, 3))  # Set the figure size if needed\n",
    "#         plt.imshow(hdul[0].data, origin='lower')\n",
    "#         # Set the DPI (dots per inch) for the figure\n",
    "#         plt.gcf().set_dpi(300)  # Adjust the DPI value as needed\n",
    "\n",
    "#         # Display the plot\n",
    "#         plt.colorbar()\n",
    "#         plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
